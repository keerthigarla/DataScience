{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "",
  "signature": "sha256:7ac41b4a493b68eeeff9a7a10ff84dab5e1ffb0b5a0226b36f114887c59c2328"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Assignment 1\n",
      "\n",
      "This assignment serves the purpose of introducing you to the basics of natural language processing and, more specifically, the natural language processing toolkit, [nltk](http://www.nltk.org/)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 1\n",
      "\n",
      "Write code to process the [Brown Corpus](http://www.nltk.org/howto/corpus.html) and answer the questions below . "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1) Write a list, named `nouns`, which contains five nouns that are more common in their plural form than their singular form. (5 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import nltk\n",
      "from nltk.corpus import brown\n",
      "\n",
      "brown_tagged_sents = brown.tagged_sents(categories='news')\n",
      "brown_sents = brown.sents(categories='news')\n",
      "unigram_tagger = nltk.UnigramTagger(brown_tagged_sents)\n",
      "unigram_tagger.tag(brown_sents[2007])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "[('Various', 'JJ'),\n",
        " ('of', 'IN'),\n",
        " ('the', 'AT'),\n",
        " ('apartments', 'NNS'),\n",
        " ('are', 'BER'),\n",
        " ('of', 'IN'),\n",
        " ('the', 'AT'),\n",
        " ('terrace', 'NN'),\n",
        " ('type', 'NN'),\n",
        " (',', ','),\n",
        " ('being', 'BEG'),\n",
        " ('on', 'IN'),\n",
        " ('the', 'AT'),\n",
        " ('ground', 'NN'),\n",
        " ('floor', 'NN'),\n",
        " ('so', 'QL'),\n",
        " ('that', 'CS'),\n",
        " ('entrance', 'NN'),\n",
        " ('is', 'BEZ'),\n",
        " ('direct', 'JJ'),\n",
        " ('.', '.')]"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2) Which word has the greatest number of distinct tags? What are they? Assign this word to the variable `g_word` and print its tag. (1 point)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3) Write a list, `tag_freq`, containing tags in order of decreasing frequency. (4 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Part 2\n",
      "\n",
      "In this part of the assignment, use the `nltk` to find the parts of speech of the sentences below. You should use three taggers to compare the different results: `pos_tag`, `UnigramTagger`, and `BiGramTagger`. Use a multi-line comment to answer the following for each example: (6 points)\n",
      "\n",
      "*Were there any mislabeled tags in any of the word tagger results? Did the three taggers tag words differently? If so, how?* (3 points each)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "1. \"The boat is going to sink and I am scared!\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "2. \"I had a dream that I found a lost dog and instead of taking it to its rightful owner, I brought it home and kept it.\" "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "3. \"I'm procrastinating my code for this assignment!\""
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Why do you think different word taggers *would* obtain different tags for the same word? Explain your answer in the markdown cell below. (5 points)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each taggers uses a different probablistic language model and specifically the Markov assumption is applied differently in each. The unigram taggers takes each word as if it is probablisitically independent from the next while the Bigram model uses conditional probability taking the previous word into consideration. Finally, the POS tagger, to my understanding, computes the probability of the word-tag given the other words and tags in the sentence. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How do you think stemming words would affect the variance-bias in word tagging? Explain your answer in the markdown cell below. (5 points)"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Stemming words would have a varied effect across the tagging schemas via the probability distribution of the word. In the unigram tagger, a stem like \"presum\" (aka, \"presume and other forms of the word). The variance would go down, but the bias would increase. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Part 3 \n",
      "\n",
      "This part will require that you write functions to normalize and stem a given input. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write a function `normalize()` that takes a string of text as input and returns a list of tokenized words in lower case format. You should not use built-in functions from `nltk` or any other natural language processing modules. (6 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Write a function `stem()` that takes a list of normalized words as input and returns **two** lists of the stemmed words -- one using the Lancaster Stemmer, the other using the Porter Stemmer. (5 points)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": null
    }
   ],
   "metadata": {}
  }
 ]
}