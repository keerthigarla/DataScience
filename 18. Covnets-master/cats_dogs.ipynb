{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "",
  "signature": "sha256:40565a2c19e83b81e9315ebd7585a66fa33f0f1b7443c6c290514f3592447c49"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import os, shutil\n",
      "#import cv2                 # working with, mainly resizing, images\n",
      "import numpy as np         # dealing with arrays\n",
      "import os                  # dealing with directories\n",
      "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
      "from tqdm import tqdm      # a nice pretty percentage bar for tasks. Thanks to viewer Daniel BA1/4hler for this suggestion\n",
      "from sklearn.model_selection import GridSearchCV, train_test_split"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The path to the directory where the original\n",
      "# dataset was uncompressed\n",
      "train_dir = '/home/keerthi/Downloads/train'\n",
      "test_dir = '/home/keerthi/Downloads/test1'\n",
      "#'/home/keerthi/ByteDev/Data Science/18. Covnets-master/train '"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Pre- processing data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#Create an one-hot encoded vector from image name \"\"\"\n",
      "\n",
      "def label_img(img):\n",
      "    word_label = img.split('.')[-3]\n",
      "    # conversion to one-hot array [cat,dog] [much cat, no dog]\n",
      "    if word_label == 'cat': return [1,0]\n",
      "    # [no cat, very doggo]\n",
      "    elif word_label == 'dog': return [0,1]   \n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from PIL import Image\n",
      "trdataX = []\n",
      "trdataY = []\n",
      "train_dir = '/home/keerthi/Downloads/cats_dogs'\n",
      "for img in tqdm(os.listdir(train_dir)):\n",
      "    trdataY.append(label_img(img))\n",
      "    img = os.path.join(train_dir, img)\n",
      "    img = Image.open(img).convert('RGBA')    \n",
      "    img = np.array(img)\n",
      "    #print(img.ndim)\n",
      "    #print(img.size)\n",
      "    #img = img.reshape((10000, 28, 28))\n",
      "    #img = img.flatten()\n",
      "    #img = img.astype('float32') / 255\n",
      "    trdataX.append([img] )\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "  0%|          | 0/1000 [00:00<?, ?it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "  4%|\u258e         | 35/1000 [00:00<00:02, 345.59it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "  9%|\u2589         | 88/1000 [00:00<00:02, 435.59it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 14%|\u2588\u258d        | 143/1000 [00:00<00:01, 472.14it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 20%|\u2588\u2589        | 199/1000 [00:00<00:01, 493.69it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 25%|\u2588\u2588\u258c       | 254/1000 [00:00<00:01, 503.47it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 31%|\u2588\u2588\u2588       | 309/1000 [00:00<00:01, 510.12it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 36%|\u2588\u2588\u2588\u258b      | 364/1000 [00:00<00:01, 514.86it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 42%|\u2588\u2588\u2588\u2588\u258f     | 417/1000 [00:00<00:01, 516.29it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 47%|\u2588\u2588\u2588\u2588\u258b     | 473/1000 [00:00<00:01, 520.57it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 53%|\u2588\u2588\u2588\u2588\u2588\u258e    | 528/1000 [00:01<00:00, 523.46it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 58%|\u2588\u2588\u2588\u2588\u2588\u258a    | 582/1000 [00:01<00:00, 524.70it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 64%|\u2588\u2588\u2588\u2588\u2588\u2588\u258e   | 636/1000 [00:01<00:00, 525.66it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 70%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588   | 700/1000 [00:01<00:00, 533.97it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 76%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258c  | 757/1000 [00:01<00:00, 536.29it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 82%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f | 815/1000 [00:01<00:00, 538.85it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 87%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258b | 872/1000 [00:01<00:00, 539.84it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 93%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258e| 929/1000 [00:01<00:00, 538.50it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        " 98%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258a| 984/1000 [00:01<00:00, 538.34it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:01<00:00, 537.11it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#print(trdataX)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X_train,X_val,Y_train,Y_val = train_test_split(trdataX,trdataY,test_size = 0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "  import keras\n",
      "keras.__version__\n",
      "\n",
      "from keras import layers\n",
      "from keras import models\n",
      "import tensorflow as tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "Using TensorFlow backend.\n"
       ]
      }
     ],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from keras import layers\n",
      "from keras import models\n",
      "\n",
      "model = models.Sequential()\n",
      "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
      "model.add(layers.MaxPooling2D((2, 2)))\n",
      "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
      "model.add(layers.MaxPooling2D((2, 2)))\n",
      "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.add(layers.Flatten())\n",
      "model.add(layers.Dense(64, activation='relu'))\n",
      "model.add(layers.Dense(10, activation='softmax'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
        "_________________________________________________________________\n",
        "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
        "_________________________________________________________________\n",
        "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
        "_________________________________________________________________\n",
        "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
        "_________________________________________________________________\n",
        "flatten_1 (Flatten)          (None, 576)               0         \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 64)                36928     \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 10)                650       \n",
        "=================================================================\n",
        "Total params: 93,322\n",
        "Trainable params: 93,322\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.compile(optimizer='rmsprop',\n",
      "              loss='categorical_crossentropy',\n",
      "              metrics=['accuracy'])\n",
      "model.fit(X_train, Y_train, epochs=5, batch_size=64)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'list' object has no attribute 'ndim'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-29-092d40babdf1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1591\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1592\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1593\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1594\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1595\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1424\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1425\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1426\u001b[0;31m                                     exception_prefix='input')\n\u001b[0m\u001b[1;32m   1427\u001b[0m         y = _standardize_input_data(y, self._feed_output_names,\n\u001b[1;32m   1428\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'DataFrame'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'ndim'"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}