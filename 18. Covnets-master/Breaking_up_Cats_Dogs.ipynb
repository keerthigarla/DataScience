{
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "name": "",
  "signature": "sha256:63351be2088b69d293adbf4853b1f84865341f5ee863cab8950e2c083a03a21f"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "import os, shutil\n",
      "#import cv2                 # working with, mainly resizing, images\n",
      "import numpy as np         # dealing with arrays\n",
      "import os                  # dealing with directories\n",
      "from random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\n",
      "from tqdm import tqdm      # a nice pretty percentage bar for tasks. Thanks to viewer Daniel BA1/4hler for this suggestion\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The path to the directory where the original\n",
      "# dataset was uncompressed\n",
      "train_dir = '/home/keerthi/Downloads/train'\n",
      "test_dir = '/home/keerthi/Downloads/test1'\n",
      "#'/home/keerthi/ByteDev/Data Science/18. Covnets-master/train '"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The directory where we will\n",
      "# store our smaller dataset\n",
      "base_dir = '/home/keerthi/ByteDev/Data Science/18. Covnets-master/cats_and_dogs_small'\n",
      "os.mkdir(base_dir)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "FileExistsError",
       "evalue": "[Errno 17] File exists: '/home/keerthi/ByteDev/Data Science/18. Covnets-master/cats_and_dogs_small'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-26-c43f5c8c899b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# store our smaller dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/keerthi/ByteDev/Data Science/18. Covnets-master/cats_and_dogs_small'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/home/keerthi/ByteDev/Data Science/18. Covnets-master/cats_and_dogs_small'"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Directories for our training,\n",
      "# validation and test splits\n",
      "train_dir = os.path.join(base_dir, 'train')\n",
      "os.mkdir(train_dir)\n",
      "validation_dir = os.path.join(base_dir, 'validation')\n",
      "os.mkdir(validation_dir)\n",
      "test_dir = os.path.join(base_dir, 'test')\n",
      "os.mkdir(test_dir)\n",
      "\n",
      "# Directory with our training cat pictures\n",
      "train_cats_dir = os.path.join(train_dir, 'cats')\n",
      "os.mkdir(train_cats_dir)\n",
      "\n",
      "# Directory with our training dog pictures\n",
      "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
      "os.mkdir(train_dogs_dir)\n",
      "\n",
      "# Directory with our validation cat pictures\n",
      "validation_cats_dir = os.path.join(validation_dir, 'cats')\n",
      "os.mkdir(validation_cats_dir)\n",
      "\n",
      "# Directory with our validation dog pictures\n",
      "validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n",
      "os.mkdir(validation_dogs_dir)\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Directory with our validation cat pictures\n",
      "test_cats_dir = os.path.join(test_dir, 'cats')\n",
      "os.mkdir(test_cats_dir)\n",
      "\n",
      "# Directory with our validation dog pictures\n",
      "test_dogs_dir = os.path.join(test_dir, 'dogs')\n",
      "os.mkdir(test_dogs_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Copy first 1000 cat images to train_cats_dir\n",
      "fnames = ['cat.{}.jpg'.format(i) for i in range(1000)]\n",
      "for fname in fnames:\n",
      "    src = os.path.join(original_dataset_dir, fname)\n",
      "    #source = \"/home/keerthi/ByteDev/Data Science/18. Covnets-master/train\"\n",
      "    #for fname in source:\n",
      "    dst = os.path.join(train_cats_dir, fname)\n",
      "    #destination = \"/home/keerthi/ByteDev/Data Science/18. Covnets-master\"\n",
      "    shutil.copyfile(src, dst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cwd = '/home/keerthi/Downloads/train'\n",
      "files = os.listdir(cwd)\n",
      "#print(\"Files in '%s': %s\" % (cwd, files))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copy next 500 cat images to validation_cats_dir\n",
      "fnames = ['cat.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
      "for fname in fnames:\n",
      "    src = os.path.join(original_dataset_dir, fname)\n",
      "    dst = os.path.join(validation_cats_dir, fname)\n",
      "    shutil.copyfile(src, dst)\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "# Copy next 500 cat images to test_cats_dir\n",
      "fnames = ['cat.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
      "for fname in fnames:\n",
      "    src = os.path.join(original_dataset_dir, fname)\n",
      "    dst = os.path.join(test_cats_dir, fname)\n",
      "    shutil.copyfile(src, dst)\n",
      "    \n",
      "# Copy first 1000 dog images to train_dogs_dir\n",
      "fnames = ['dog.{}.jpg'.format(i) for i in range(1000)]\n",
      "for fname in fnames:\n",
      "    src = os.path.join(original_dataset_dir, fname)\n",
      "    dst = os.path.join(train_dogs_dir, fname)\n",
      "    shutil.copyfile(src, dst)\n",
      "    \n",
      "# Copy next 500 dog images to validation_dogs_dir\n",
      "fnames = ['dog.{}.jpg'.format(i) for i in range(1000, 1500)]\n",
      "for fname in fnames:\n",
      "    src = os.path.join(original_dataset_dir, fname)\n",
      "    dst = os.path.join(validation_dogs_dir, fname)\n",
      "    shutil.copyfile(src, dst)\n",
      "    \n",
      "# Copy next 500 dog images to test_dogs_dir\n",
      "fnames = ['dog.{}.jpg'.format(i) for i in range(1500, 2000)]\n",
      "for fname in fnames:\n",
      "    src = os.path.join(original_dataset_dir, fname)\n",
      "    dst = os.path.join(test_dogs_dir, fname)\n",
      "    shutil.copyfile(src, dst)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a sanity check, let's count how many pictures we have in each training split (train/validation/test):"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('total training cat images:', len(os.listdir(train_cats_dir)))\n",
      "print('total training dog images:', len(os.listdir(train_dogs_dir)))\n",
      "print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n",
      "print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n",
      "print('total test cat images:', len(os.listdir(test_cats_dir)))\n",
      "print('total test dog images:', len(os.listdir(test_dogs_dir)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total training cat images: 1000\n",
        "total training dog images: 1000\n",
        "total validation cat images: 500\n",
        "total validation dog images: 500\n",
        "total test cat images: 500\n",
        "total test dog images: 500\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Pre- processing data"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#Create an one-hot encoded vector from image name \"\"\"\n",
      "\n",
      "def label_img(img):\n",
      "    word_label = img.split('.')[-3]\n",
      "    # conversion to one-hot array [cat,dog] [much cat, no dog]\n",
      "    if word_label == 'cat': return np.array([1,0])\n",
      "    # [no cat, very doggo]\n",
      "    elif word_label == 'dog': return np.array([0,1])   "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from PIL import Image\n",
      "def create_train_data():\n",
      "    trdata = []\n",
      "    train_dir = '/home/keerthi/Downloads/cats_dogs'\n",
      "    for img in tqdm(os.listdir(train_dir)):\n",
      "        img = os.path.join(train_dir, img)\n",
      "        img = Image.open(img).convert('RGBA')\n",
      "        img = np.array(img)\n",
      "        #img = img.reshape((10000, 28, 28, 1))\n",
      "        img = img.flatten()\n",
      "        #img = img.astype('float32') / 255\n",
      "        trdata.append([img,label_img(img)] )\n",
      "        #trdata.append(np.array(os.path.join(train_dir, img)))\n",
      "    #shuffle(training_data)\n",
      "    #np.save('train_data.npy', trdata)\n",
      "    return trdata\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = create_train_data()\n",
      "#print(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\r",
        "  0%|          | 0/1000 [00:00<?, ?it/s]"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "ename": "AttributeError",
       "evalue": "'numpy.ndarray' object has no attribute 'split'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-17-d044d4171508>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-16-a8210c17a37c>\u001b[0m in \u001b[0;36mcreate_train_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#img = img.astype('float32') / 255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtrdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;31m#trdata.append(np.array(os.path.join(train_dir, img)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m#shuffle(training_data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-3-395af99902a6>\u001b[0m in \u001b[0;36mlabel_img\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlabel_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mword_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# conversion to one-hot array [cat,dog] [much cat, no dog]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mword_label\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'cat'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'split'"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X= df.drop(['price'], axis = 1)\n",
      "X_train,X_val,Y_train,Y_val = train_test_split(X,df['price'],test_size = 0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "  import keras\n",
      "keras.__version__\n",
      "\n",
      "from keras import layers\n",
      "from keras import models\n",
      "import tensorflow as tf"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# from keras import layers\n",
      "from keras import models\n",
      "\n",
      "model = models.Sequential()\n",
      "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
      "model.add(layers.MaxPooling2D((2, 2)))\n",
      "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
      "model.add(layers.MaxPooling2D((2, 2)))\n",
      "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.add(layers.Flatten())\n",
      "model.add(layers.Dense(64, activation='relu'))\n",
      "model.add(layers.Dense(10, activation='softmax'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "_________________________________________________________________\n",
        "Layer (type)                 Output Shape              Param #   \n",
        "=================================================================\n",
        "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
        "_________________________________________________________________\n",
        "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
        "_________________________________________________________________\n",
        "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
        "_________________________________________________________________\n",
        "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
        "_________________________________________________________________\n",
        "conv2d_3 (Conv2D)            (None, 3, 3, 64)          36928     \n",
        "_________________________________________________________________\n",
        "flatten_1 (Flatten)          (None, 576)               0         \n",
        "_________________________________________________________________\n",
        "dense_1 (Dense)              (None, 64)                36928     \n",
        "_________________________________________________________________\n",
        "dense_2 (Dense)              (None, 10)                650       \n",
        "=================================================================\n",
        "Total params: 93,322\n",
        "Trainable params: 93,322\n",
        "Non-trainable params: 0\n",
        "_________________________________________________________________\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from keras.datasets import mnist\n",
      "from keras.utils import to_categorical\n",
      "\n",
      "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
      "\n",
      "train_images = train_images.reshape((60000, 28, 28, 1))\n",
      "train_images = train_images.astype('float32') / 255\n",
      "\n",
      "test_images = test_images.reshape((10000, 28, 28, 1))\n",
      "test_images = test_images.astype('float32') / 255\n",
      "\n",
      "train_labels = to_categorical(train_labels)\n",
      "test_labels = to_categorical(test_labels)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}